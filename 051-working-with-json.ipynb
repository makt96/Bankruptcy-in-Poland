{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78d9f567-51b4-477b-ae34-ae94b4404c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e757126-5ebb-4283-a3e9-2bd59cc3d848",
   "metadata": {},
   "source": [
    "## Prepare Data \n",
    "\n",
    "The first thing we need to do is access the file that contains the data we need. We've done this using multiple strategies before, but this time around, we're going to use the command line.\n",
    "\n",
    " Open a terminal window and navigate to the directory where the data for this project is located.\n",
    "\n",
    "What's the Linux command line?\n",
    "Navigate a file system using the Linux command line.\n",
    "As we've seen in our other projects, datasets can be large or small, messy or clean, and complex or easy to understand. Regardless of how the data looks, though, it needs to be saved in a file somewhere, and when that file gets too big, we need to compress it. Compressed files are easier to store because they take up less space. If you've ever come across a ZIP file, you've worked with compressed data.\n",
    "\n",
    "The file we're using for this project is compressed, so we'll need to use a file utility called gzip to open it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6b7917-b512-4002-97ab-b202b711ea13",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd data\n",
    "gzip -dfk poland-bankruptcy-data-2009.json.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d5a84f-14a4-49a8-93c6-1603cf4808fb",
   "metadata": {},
   "source": [
    "## Explore\n",
    "\n",
    "Now that we've decompressed the data, let's take a look and see what's there.\n",
    "\n",
    "In the terminal window, examine the first 10 lines of poland-bankruptcy-data-2009.json.\n",
    "\n",
    "Load the data into a DataFrame.\n",
    "\n",
    "Read a JSON file into a DataFrame using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b7b064-43a2-435b-a7c6-bd0a79520eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"data/poland-bankruptcy-data-2009.json\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e20d0a-fbc2-43e9-bce9-1e945ae6c0cf",
   "metadata": {},
   "source": [
    "\n",
    "Hmmm. It looks like something went wrong, and we're going to have to fix it. Luckily for us, there's an error message to help us figure out what's happening here:\n",
    "\n",
    "ValueError: Mixing dicts with non-Series may lead to ambiguous ordering.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec6902c-ed22-411a-be69-e87841af7685",
   "metadata": {},
   "source": [
    "*** Using a context manager, open the file poland-bankruptcy-data-2009.json and load it as a dictionary with the variable name poland_data.\n",
    "\n",
    "What's a context manager?\n",
    "Open a file in Python.\n",
    "Load a JSON file into a dictionary using Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e7485f-d463-4294-895b-5183f3bba1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open file and load JSON\n",
    "with open(\"data/poland-bankruptcy-data-2009.json\",\"r\") as read_file:\n",
    "    poland_data = json.load(read_file)\n",
    "\n",
    "print(type(poland_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d94c167-937f-41d8-a95d-54bd4e711fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print `poland_data` keys\n",
    "poland_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32722f2a-e722-428e-8260-f97f046f8ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue Exploring `poland_data`\n",
    "#poland_data[\"metadata\"]\n",
    "#poland_data[\"schema\"].keys()\n",
    "#type(poland_data[\"data\"])\n",
    "poland_data[\"data\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641c6764-1141-4afe-96f9-3368b378b372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of companies\n",
    "len(poland_data[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9644866-623c-4739-93f1-3f8be8ca78ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of features\n",
    "len(poland_data[\"data\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5ec77f-6dbb-4ab4-8b77-d318b4496a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through companies\n",
    "for item in poland_data[\"data\"]:\n",
    "    if len(item) != 66:\n",
    "        print(\"ALERT!!\")\n",
    "print(\"All Data Has 66 Columns/Features\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb007e9c-4eb9-41fb-a145-b6ec3f24bdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open compressed file and load contents\n",
    "with gzip.open(\"data/poland-bankruptcy-data-2009.json.gz\",\"r\") as read_file:\n",
    "    poland_data_gz = json.load(read_file)\n",
    "\n",
    "print(type(poland_data_gz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f5795a-1893-44e2-ba8c-e3f62728e70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore `poland_data_gz`\n",
    "print(poland_data_gz.keys())\n",
    "print(len(poland_data_gz[\"data\"]))\n",
    "print(len(poland_data_gz[\"data\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bd78e5-0569-4b71-9d29-58dbed900380",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame().from_dict(poland_data_gz[\"data\"]).set_index(\"company_id\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e260518-57c5-495e-b0b7-e000e8a2071b",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c31cd3-9cc5-4ef2-93a4-fa339b4f64a6",
   "metadata": {},
   "source": [
    "Now that we have everything set up the way we need it to be, let's combine all these steps into a single function that will decompress the file, load it into a DataFrame, and return it to us as something we can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c302df6a-071e-46d9-91fc-c50086bbe3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle(filename):\n",
    "    # Open compressed file, load into dict\n",
    "    with gzip.open(filename, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Turn dict into Dataframe\n",
    "    df = pd.DataFrame().from_dict(data[\"data\"]).set_index(\"company_id\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db75605c-07d1-4897-ba0d-9d38d2c74ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = wrangle(\"data/poland-bankruptcy-data-2009.json.gz\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
