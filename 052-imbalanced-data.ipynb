{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f72319d-53df-406a-938f-44ea18e426d0",
   "metadata": {},
   "source": [
    "<font size=\"+3\"><strong>Imbalanced Data</strong></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af850f1d-c25f-4ad2-bad2-998e3857b111",
   "metadata": {},
   "source": [
    "In the last lesson, we prepared the data. \n",
    "\n",
    "In this lesson, we're going to explore some of the features of the dataset, use visualizations to help us understand those features, and develop a model that solves the problem of imbalanced data by under- and over-sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d22b499-7de4-4055-8613-fc19f078d628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b7dcfe-a2f9-4ce1-bacc-3ba7afacece2",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcca9662-9a40-4fcc-8cde-af9555c48f18",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6aaa7b7-9e6c-4986-8f8b-332e8ba0e358",
   "metadata": {},
   "source": [
    "As always, we need to begin by bringing our data into the project, and the function we developed in the previous module is exactly what we need."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2977e0a6-eccf-4bdf-b184-eb70b0d841c8",
   "metadata": {},
   "source": [
    " Complete the `wrangle` function below using the code you developed in the last lesson. Then use it to import `poland-bankruptcy-data-2009.json.gz` into the DataFrame `df`.\n",
    "\n",
    "- [<span id='technique'>Write a function in <span id='tool'>Python</span></span>.](../%40textbook/02-python-advanced.ipynb#Functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb35777-50c4-43b1-829a-fda6f4de773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle(filename):\n",
    "    \n",
    "    # Open compressed file, load into dictionary\n",
    "    with gzip.open(filename, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    # Load dictionary into DataFrame, set index\n",
    "    df = pd.DataFrame().from_dict(data[\"data\"]).set_index(\"company_id\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5eeba5-dad9-4e50-a8af-0cbc5c4f55ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = wrangle(\"data/poland-bankruptcy-data-2009.json.gz\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9576d4f-b03d-4364-80ef-6108028d7fb7",
   "metadata": {},
   "source": [
    "## Explore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe95957e-fb6a-4aa9-ae09-e21e4d20b426",
   "metadata": {},
   "source": [
    "Let's take a moment to refresh our memory on what's in this dataset. In the last lesson, we noticed that the data was stored in a JSON file (similar to a Python dictionary), and we explored the key-value pairs. This time, we're going to look at what the values in those pairs actually are."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476786a6-6f5b-4619-bfc3-654caa4cdf6c",
   "metadata": {},
   "source": [
    " Use the `info` method to explore `df`. What type of features does this dataset have? Which column is the target? Are there columns will missing values that we'll need to address?\n",
    "\n",
    "- [Inspect a DataFrame using the `shape`, `info`, and `head` in pandas.](../%40textbook/03-pandas-getting-started.ipynb#Inspecting-DataFrames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c2c636-fab4-4b04-8479-44e13e996608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect DataFrame\n",
    "#df.info()\n",
    "df.isnull().sum() / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53e1dfc-24e6-444b-b18e-4a9035a28bde",
   "metadata": {},
   "source": [
    "That's solid information. We know all our features are numerical and that we have missing data. But, as always, it's a good idea to do some visualizations to see if there are any interesting trends or ideas we should keep in mind while we work. First, let's take a look at how many firms are bankrupt, and how many are not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd80107e-5b15-40b5-ada6-32720a9ce274",
   "metadata": {},
   "source": [
    "Create a bar chart of the value counts for the `\"bankrupt\"` column. You want to calculate the relative frequencies of the classes, not the raw count, so be sure to set the `normalize` argument to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4db28e0-e9fb-46e0-b1af-68e262fb391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot class balance\n",
    "df[\"bankrupt\"].value_counts(normalize=True).plot(\n",
    "    kind=\"bar\",\n",
    "    xlabel=\"Bankrupt\",\n",
    "    ylabel=\"Frequency\",\n",
    "    title=\"Class Balance\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e8b84f-d991-47f4-ae1d-0e74dfd56a16",
   "metadata": {},
   "source": [
    "That's good news for Poland's economy! Since it looks like most of the companies in our dataset are doing all right for themselves, let's drill down a little farther. However, it also shows us that we have an imbalanced dataset, where our majority class is far bigger than our minority class.\n",
    "\n",
    "In the last lesson, we saw that there were 64 features of each company, each of which had some kind of numerical value. It might be useful to understand where the values for one of these features cluster, so let's make a boxplot to see how the values in `\"feat_27\"` are distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07ecf47-6cec-49b4-a559-3afd393fff40",
   "metadata": {},
   "source": [
    "Use seaborn to create a boxplot that shows the distributions of the `\"feat_27\"` column for both groups in the `\"bankrupt\"` column. Remember to label your axes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044597ce-013f-4985-83c2-827dfb926a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boxplot\n",
    "sns.boxplot(x=\"bankrupt\", y=\"feat_27\",data=df)\n",
    "plt.xlabel(\"Bankrupt\")\n",
    "plt.ylabel(\"POA / financial expenses\")\n",
    "plt.title(\"Distribution of Profit/Expenses Ratio, by Class\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023bdc3c-182e-43da-a77c-4ed8f20a7171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for `feat_27`\n",
    "df[\"feat_27\"].describe().apply(\"{0:,.0f}\".format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce33e8e4-331d-4155-af73-de5a6f26636b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of `feat_27`\n",
    "df[\"feat_27\"].hist()\n",
    "plt.xlabel(\"POA / financial expenses\")\n",
    "plt.ylabel(\"Count\"),\n",
    "plt.title(\"Distribution of Profit/Expenses Ratio\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d60e0bd-480f-406c-a8d3-d747241ac880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create clipped boxplot\n",
    "q1,q9 = df[\"feat_27\"].quantile([0.1,0.9])\n",
    "mask = df[\"feat_27\"].between(q1,q9)\n",
    "#mask.head()\n",
    "sns.boxplot(x=\"bankrupt\", y=\"feat_27\", data=df[mask])\n",
    "plt.xlabel(\"Bankrupt\")\n",
    "plt.ylabel(\"POA / financial expenses\")\n",
    "plt.title(\"Distribution of Profit/Expenses Ratio, by Bankruptcy Status\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c57bf7-2893-428b-8461-c23ff95d23e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.drop(columns=\"bankrupt\").corr()\n",
    "#corr.head()\n",
    "sns.heatmap(corr);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8909ff-2b36-4c03-b687-d3b48b47fdf1",
   "metadata": {},
   "source": [
    "So what did we learn from this EDA? First, our data is imbalanced. This is something we need to address in our data preparation. Second, many of our features have missing values that we'll need to impute. And since the features are highly skewed, the best imputation strategy is likely median, not mean. Finally, we have autocorrelation issues, which means that we should steer clear of linear models, and try a tree-based model instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548d3897-9c93-41f4-83f4-f0d0afb342c7",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b19eb3c-1230-424b-8764-4f6a06edc666",
   "metadata": {},
   "source": [
    "So let's start building that model. If you need a refresher on how and why we split data in these situations, take a look back at the Time Series module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee3cc2b-7277-4072-b059-51604ab16119",
   "metadata": {},
   "source": [
    " Create your feature matrix `X` and target vector `y`. Your target is `\"bankrupt\"`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6e4a58-cab3-44ca-aa76-60658798844d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"bankrupt\"\n",
    "X = df.drop(columns=target)\n",
    "y = df[target]\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1c33ff-3c09-4f7b-ae0c-d6d4a097d0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,y, test_size = 0.2, random_state = 42\n",
    ")\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc3cedc-b629-4d44-aeac-a8e6abc1d4bf",
   "metadata": {},
   "source": [
    "## Resample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2c3100-3479-4faa-b4cb-c4ccaf7f2ef5",
   "metadata": {},
   "source": [
    "Now that we've split our data into training and validation sets, we can address the class imbalance we saw during our EDA. One strategy is to resample the training data. (This will be different than the resampling we did with time series data ) There are many to do this, so let's start with under-sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b329ad-7930-4a22-84eb-b4eba49ea5db",
   "metadata": {},
   "source": [
    "Create a new feature matrix `X_train_under` and target vector `y_train_under` by performing random under-sampling on your training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252ac1d0-ca6e-4daf-8d53-eb356ada12b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "under_sampler = RandomUnderSampler(random_state=42)\n",
    "X_train_under, y_train_under = under_sampler.fit_resample(X_train,y_train)\n",
    "print(X_train_under.shape)\n",
    "X_train_under.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bdc3f9-5493-458b-8cc7-428917d0c999",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_under.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c92307-b2eb-468c-9649-ef49cc514282",
   "metadata": {},
   "source": [
    " Create a new feature matrix `X_train_over` and target vector `y_train_over` by performing random over-sampling on your training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d69a02e-beae-4771-906c-d8f86f157038",
   "metadata": {},
   "outputs": [],
   "source": [
    "over_sampler = RandomOverSampler(random_state=42)\n",
    "X_train_over, y_train_over = over_sampler.fit_resample(X_train,y_train)\n",
    "print(X_train_over.shape)\n",
    "X_train_over.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d594ad-728f-441c-801e-69e6db45de93",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_over.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8888e4-c5ae-40bc-8526-f8e9da59610a",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec2cd15-cb93-4e66-9bf3-7e8e2e31d4dc",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a6ad96-564a-4042-b5f9-bab9676b3cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
